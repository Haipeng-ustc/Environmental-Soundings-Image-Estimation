{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wx5NjSggzYo"
   },
   "source": [
    "*italicized text*# Lab 1 - Introduction to optimization and operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2NUZHK5ogzYo",
    "outputId": "5588ed9e-2d6f-4274-e7bd-22b687c4aac1"
   },
   "outputs": [],
   "source": [
    "#!python -m pip install \"sepPlot @ git+http://zapad.stanford.edu/bob/pySepPlot.git@bd033869d29e5202212d81a285c27bfdc5907780\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FV4WvT1gzYp",
    "outputId": "9bd87ba4-ef4c-4758-fcfa-5090ce030975"
   },
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/rgclapp007/GEE-lab1/main/bay.H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTjMAgPZgzYq"
   },
   "source": [
    "## Abstract\n",
    "\n",
    "Here we will look at the general formulation of a linear optimization problem. We will define the model space, data space and the mapping matrix \n",
    "and focus on the properties of such a matrix. Then, we will look at operators and how to analyze them. Finally, we will apply a few roughening\n",
    "operators to the topography map of the Bay area and interpret and analyze both the results and the operators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h87sgGfngzYq"
   },
   "source": [
    "## Linear optimization\n",
    "In any scientific experiment, we try to measure a certain property or attribute. If we are lucky, that attribute can be measured directly.\n",
    "Unfortunately, this is rarely the case. In general, we end up measuring another attribute that is not exactly what we want, but is related to\n",
    "it by physical equations. Going from the attribute that we want to the attribute that we measure is considered the forward problem. The goal of\n",
    "optimization is to go in the inverse direction, i.e. to obtain (or estimate) the model what we want from the data that we measure, by means of\n",
    "solving physical equations.\n",
    "\n",
    "Before we can invert our measurements, we first need to formulate the forward problem. In the framework of optimization, we define the\n",
    "*model space* as the set of physical attributes that we want, and the *data space* as the physical attributes that we measure.\n",
    "Everything else, including the physical equations, acquisition parameters or any auxiliary parameters, will be included in the mapping \n",
    "matrix. Once we defined these components, we can write any linear forward process as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "d = F m,\n",
    "\\end{equation*}\n",
    "\n",
    "where the vector $\\mathbf d$ represents the data, the vector $\\mathbf m$ represents the model, and the matrix $\\mathbf F$ represents the\n",
    "corresponding mapping operator. Equation 1 is only valid if the data space is linearly related to the model space, i.e. if the matrix\n",
    "$\\mathbf F$ is independent of the model vector $\\mathbf m$. Notice that the size of the matrix $\\mathbf F$ is determined by the size of the model\n",
    "and data spaces. For instance, if the size of the model space is ${\\rm Nm} \\times 1$ and the size of data space is ${\\rm Nd} \\times 1$, then the\n",
    "size of the mapping matrix is ${\\rm Nd} \\times {\\rm Nm}$. Keep in mind that the model space and the data space are always portrayed as vectors of\n",
    "size ${\\rm N} \\times 1$, regardless of the physical dimensionality.\n",
    "\n",
    "The mapping matrix $\\mathbf F$ converts a model vector into a data vector, in a process denominated *forward modeling*. We can get some\n",
    "insight of such a process by looking  at the size of such a\n",
    "matrix and analyzing which elements are non-zero, without actually looking at those non-zero values. For instance, a tall-thin matrix means that\n",
    "the data space is larger than the model space, hence mapping from the model to the data includes significant spraying or scattering. The\n",
    "larger data space too implies that the data cannot be exactly fit because of the presence of a non-trivial data null space (Aster,2013).\n",
    "On the other hand, a short-wide matrix means that data space is smaller than the model space, hence mapping from the model to the data includes\n",
    "significant summing or stacking. The larger model space too implies that several models can fit the data (Aster,2013). If the matrix is diagonal,\n",
    "then each data point is only a scaled version of one corresponding model point, which is called scaling. If the matrix has non-zero values in\n",
    "non-diagonal elements, then each data point is a linear combination of several model points, which is called filtering. If each column is the same\n",
    "as the previous column but shifted down by one element, the process is considered stationary. In the worst-case scenario, all the elements are non-zero,\n",
    "but this situation rarely occurs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rroJW1Zz8YEy"
   },
   "source": [
    "## Operators\n",
    "The most direct way to perform forward modeling is saving matrix $\\mathbf F$ and applying matrix-vector multiplication. However, in most of geophysical\n",
    "problems the matrix is very sparse, i.e. most of its elements are zeros. Moreover, many processes are stationary, i.e., the same coefficients are\n",
    "repeated over and over in every column. Therefore, instead of saving the whole matrix we can implement a procedure that loops through the elements\n",
    "of the model and the data, utilizing only the non-zero matrix elements on the fly. This efficient implementation makes use of an *operator* that\n",
    "corresponds to the matrix. In simple cases, each operator loop is similar to applying one row (or column) of the matrix. Notice that neither do we save\n",
    "the elements of the matrix, nor compute any unnecessary elements. Also, since operators do not use matrix-vector multiplication, we do not have to convert\n",
    "the data and model to vectors.\n",
    "\n",
    "However, since we do not construct matrix ${\\mathbf F}$ directly, it is often difficult to understand the behavior of the corresponding operator by just\n",
    "looking at the code, especially for complicated operators. The solution isto find the operator filter's response, also called point-spread function (PSF).\n",
    "The filter's response is computed by applying the operator on a model consisting on zeros and a single spike at one location. The output corresponds to\n",
    "the column of the matrix $\\mathbf F$ of that location. If the operator is a scalar, the output should have values at one location only. If the operator is\n",
    "a filter, the output should have values at more than one location. If the operator is stationary, the filter response would be the same for all locations\n",
    "of the spike (the model edges might be an exception)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xh_NqegBgzYs"
   },
   "source": [
    "## Your assignment\n",
    "\n",
    "You will be working with a dataset that shows elevation arround the bay area.  We  will begin by reading in the dataset into a SepVector object. We begin by importing the SepVector and genericIO modules. We then read in the data into a sepVector object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbqVlLBAgzYs",
    "outputId": "2a82528f-6b34-4823-b24d-2e900cb8c9ac"
   },
   "outputs": [],
   "source": [
    "import sepPython.modes        #Import SEP python module\n",
    "io=sepPython.modes.defaultIO  #Get default IO that expects SEPlib datasets and uses sepVectors\n",
    "\n",
    "bay=io.vectorFromStorage(\"./bay.H\")\n",
    "b=bay.getNdArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8oCLTddgzYt"
   },
   "source": [
    "We can view the data by using the sepPlot module's Grey function.  We mark the cell to make an interative graphics cell using \"%matplotlib ipympl\". We import the matplotlib module which handles python graphics. We pass the **plt** object along with our **sepVector** object to Grey function. We've passed two additional arguments to display the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "id": "K6PXrGJxgzYu",
    "outputId": "7962db1a-479d-4de2-951d-e15568519c0a"
   },
   "outputs": [],
   "source": [
    "from sepPlot import Grey\n",
    "\n",
    "grey=Grey(bay,label1=\"N-S\",label2=\"E-W\",width=500,height=700)\n",
    "grey.image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcQWVrtbgzYu"
   },
   "source": [
    "Next we will apply a series of operators to the image to see if we can gain new insignts into our map.  Each operator will inherit from a python base class that we will be using throughout the quarter.  Our first operator will apply a derivative in the North-South direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfuE7_dngzYu"
   },
   "outputs": [],
   "source": [
    "from genericSolver.pyOperator import Operator\n",
    "from genericSolver import pyVector\n",
    "from numba import jit\n",
    "\n",
    "class deriv1(Operator):\n",
    "    \"\"\"A simple operator that applies a derivative along the fast axis\"\"\"\n",
    "    def __init__(self,domain):\n",
    "        \"\"\"Initialization an operator \"\"\"\n",
    "        \n",
    "        if not isinstance(domain,pyVector.vector): \n",
    "            raise Exception(\"Expecting a python vector\")\n",
    "        \n",
    "        #Store that vector space of the domain and range\n",
    "        super().__init__(domain,domain)\n",
    "        \n",
    "    def forward(self,add,model,data):\n",
    "        \"\"\"Apply the operator\n",
    "           add - boolean whether or not add to the data vector or zero it first\n",
    "           model - model space (domain)\n",
    "           data  - data space (range)\"\"\"\n",
    "        \n",
    "        #Make sure the model and data match the vectorspace the operator was initialized with\n",
    "        self.checkDomainRange(model,data)\n",
    "        \n",
    "        #Zero the data if add -false\n",
    "        if not add:\n",
    "            data.zero()\n",
    "        \n",
    "        forward2D_1(model.getNdArray(),data.getNdArray())\n",
    "\n",
    "        \n",
    "    def adjoint(self,add,model,data):\n",
    "        \"\"\"Apply the adjoint of the operator\n",
    "           add - boolean whether or not add to the data vector or zero it first\n",
    "           model - model space (domain)\n",
    "           data  - data space (range)\"\"\"\n",
    "        \n",
    "        raise Exception(\"Not implemented for now\")\n",
    "\n",
    "        \n",
    "@jit(nopython=True)\n",
    "def forward2D_1(model, data):\n",
    "    for i2 in range(model.shape[0]):\n",
    "        for i in range(1, model.shape[1]):\n",
    "            data[i2,i] += model[i2,i] - model[i2,i - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCc9jMjzgzYv"
   },
   "source": [
    "We can the apply our new operator to the view of the bay and look at the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "mps2uRg7gzYv",
    "outputId": "13aac6d4-f932-4c94-db89-cf98ff115ff6"
   },
   "outputs": [],
   "source": [
    "#make a copy of the bay vector\n",
    "out=bay.clone()\n",
    "\n",
    "#create a version of the operaor\n",
    "op=deriv1(bay)\n",
    "\n",
    "#Apply the operator\n",
    "op.forward(False,bay,out)\n",
    "\n",
    "#View the result\n",
    "outP=Grey(out,label1=\"N-S\",label2=\"E-W\",width=500,height=700)\n",
    "outP.image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93tOaE5JgzYv"
   },
   "source": [
    "## Questions (part 1)\n",
    "\n",
    "1. Write a python-code for a matrix-vector multiply using loops.\n",
    "\n",
    "2.  How do we know if a matrix or operator is linear? Please recall your Linear Algebra course!\n",
    "\n",
    "3. Given a simple line fitting problem where you have the values $\\mathbf y = \\{y1, y2, y3\\}$ and the coordinates $\\mathbf x = \\{x1, x2, x3\\}$, and\n",
    "we want to fit a line with slope $a$ and y-intercept $b$ such as $\\mathbf y = a \\mathbf x + b$\n",
    "\n",
    "  a. What is the data space, model space and the mapping matrix (write out all the elements)?\n",
    "\n",
    "  b. Given that we are fitting a line, is $\\mathbf y$ linearly related to $\\mathbf x$? Show your proof.\n",
    "\n",
    "4. In the relationship $\\mathbf y = a \\mathbf x^2$, is $\\mathbf y$ linearly related to $\\mathbf x$? If not, how can you reformulate it to make it so?\n",
    "\n",
    "5.  Assume that the data is three dimensional $d(x_1, x_2, t)$ and model is two dimensional $m(y_1, y_2)$:\n",
    "\n",
    "   a. How do you convert the model and data to the form $\\mathbf d = \\mathbf F \\mathbf m$?\n",
    "\n",
    "   b. What would the sizes of $\\mathbf d$, $\\mathbf F$ and $\\mathbf m$ be? Use a prefix $\\rm N$ to indicate size, .e.g. $\\rm Nx_1$.\n",
    "\n",
    "6. Assume that the data is one dimensional $d(x_1)$ and model is also one dimensional $m(x_1)$ and the operation we want to apply is first-order\n",
    "backward finite difference (look it up if you do not already know it). Show the computational cost (size of memory required, number of summations and\n",
    "multiplications) of doing a matrix-vector multiply.\n",
    "\n",
    "7. Redo the same previous question but with operators instead of matrix-vector multiply.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Write a python-code for a matrix-vector multiply using loops.\n",
    "import numpy as np\n",
    "\n",
    "def matVecMult(v, m, y, add = False):\n",
    "    \n",
    "    if m.shape[0] != y.shape[0]:\n",
    "        raise ValueError('m.shape[0] should be equal to y.shape[0]')\n",
    "    if m.shape[1] != v.shape[0]:\n",
    "        raise ValueError('m.shape[1] should be equal to v.shape[0]') \n",
    "    \n",
    "    if not add:\n",
    "        y[:] = 0.0\n",
    "    \n",
    "    for i in range(m.shape[0]):\n",
    "        for j in range(m.shape[1]):\n",
    "            y[i] += m[i][j] * v[j]\n",
    "                    \n",
    "d1 = 10\n",
    "d2 = 20\n",
    "m = np.ones((d2, d1))\n",
    "v = np.ones(d1)\n",
    "y = np.ones(d2)\n",
    "\n",
    "matVecMult(v, m, y, add = False)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. If the matrix or operator is not related to the model, then it is linear. Otherwise, it is considered as a nonlinear problem since the matrix or operator includes the model parameters. Mathmatically, with $\\mathbf d = \\mathbf F (\\mathbf m)$, we can test the following relationships: $ \\alpha \\mathbf d = \\mathbf F (\\alpha \\mathbf m)$ and $ \\alpha \\mathbf d_1 + \\beta \\mathbf d_2  = \\mathbf F (\\alpha \\mathbf m_1 + \\beta  \\mathbf m_2 ) = \\alpha\\mathbf F( \\mathbf m_1) +  \\beta  \\mathbf F(\\mathbf m_2 )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In the form of $\\mathbf d = \\mathbf F \\mathbf m$, this problem can be written as\n",
    "$$\n",
    "\\left(\\begin{array}{l}\n",
    "y1  \\\\\n",
    "y2  \\\\\n",
    "y3\n",
    "\\end{array}\\right) =\n",
    "\\left(\\begin{array}{ll}\n",
    "     x1 & 1 \\\\ \n",
    "     x2 & 1 \\\\\n",
    "     x3 & 1\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{l}\n",
    "a \\\\\n",
    "b\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "where the model space is $ m = [a, b]^{T} $, the data space is $ d = [y1, y2, y3]^T $, and the mapping matrix is \n",
    "$\n",
    "F = \\left(\\begin{array}{llllll}\n",
    "     x1 & 1 \\\\ \n",
    "     x2 & 1 \\\\\n",
    "     x3 & 1\n",
    "\\end{array}\\right)\n",
    "$. \\\n",
    "$\\mathbf y$ is not linearly related to $\\mathbf x$. Given a new $x^* = \\alpha x$ with $\\alpha \\neq 0$, there is $y^* = ax^* +b = a\\alpha x + b \\neq \\alpha (ax +b)$. Therefore, $\\mathbf y$ is not linearly related to $\\mathbf x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. In the relationship $\\mathbf y = a \\mathbf x^2$,  $\\mathbf y$ is not linearly related to $\\mathbf x$. To make it so, I would like to assign $\\mathbf x^2$ to a new variable such as $x^* = \\mathbf x^2$. Thus, \n",
    "in the new relationship $\\mathbf y = a x^*$,  $\\mathbf y$ is linearly related to $x^*$, with $x^* = \\mathbf x^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "5. I will first flatten both the data and model to be 1-D vectors. For example, the 1-D data vector is\n",
    "$$\n",
    "d^* = [d_{t_1}^{(1, 1)}, ..., d_{t_{Nt}}^{(1, 1)}, d_{t_1}^{(1, 2)}, ..., d_{t_{Nt}}^{(1, Nx_2)}, ..., d_{t_{Nt}}^{(Nx_1, Nx_2)}]^{T}\n",
    "$$\n",
    "the 1-D model vector is\n",
    "$$\n",
    "m^* = [m_{1, 1}, ..., m_{1, Ny_2}, m_{2, 1}, ..., m_{Ny_1, Ny_2}]\n",
    "$$ \\\n",
    "The size of $\\mathbf d $ will be $Nx_{1}  Nx_{2}  Nt$, the size of $\\mathbf m $ will be $Ny_1  Ny_2$, and the size of $\\mathbf F$ will be $Nx_{1}  Nx_{2}  Nt * Ny_1 Ny_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. In the matrix-vector multiply with the full matrix form, there will be $ (2 Nx_{1} + {Nx_{1}}^2)*SizePerDataType$ memory required, and there will be a total number of ${Nx_{1}}^2$ summations and ${Nx_{1}}^2$ multiplications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. In this case, there will be $ (2 Nx_{1})*SizePerDataType$ memory required, and there will be a total number of ${Nx_{1}}$ summations and no multiplication will be involved, if ignoring the first element (or last element)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdorResZgzYw"
   },
   "source": [
    "## Part 2\n",
    "\n",
    "Make two new classes that take a derivative in the E-W direction and one that applies a lapacian to the image. Define the classes in python and then apply them to the image of the bay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genericSolver.pyOperator import Operator\n",
    "from genericSolver import pyVector\n",
    "from numba import jit\n",
    "\n",
    "class deriv_EW(Operator):\n",
    "    \"\"\"A simple operator that applies a derivative along the slow axis\"\"\"\n",
    "    def __init__(self,domain):\n",
    "        \"\"\"Initialization an operator \"\"\"\n",
    "        \n",
    "        if not isinstance(domain,pyVector.vector): \n",
    "            raise Exception(\"Expecting a python vector\")\n",
    "        \n",
    "        #Store that vector space of the domain and range\n",
    "        super().__init__(domain,domain)\n",
    "        \n",
    "    def forward(self,add,model,data):\n",
    "        \"\"\"Apply the operator\n",
    "           add - boolean whether or not add to the data vector or zero it first\n",
    "           model - model space (domain)\n",
    "           data  - data space (range)\"\"\"\n",
    "        \n",
    "        #Make sure the model and data match the vectorspace the operator was initialized with\n",
    "        self.checkDomainRange(model,data)\n",
    "        \n",
    "        #Zero the data if add -false\n",
    "        if not add:\n",
    "            data.zero()\n",
    "        \n",
    "        forward2D_EW(model.getNdArray(),data.getNdArray())\n",
    "\n",
    "        \n",
    "    def adjoint(self,add,model,data):\n",
    "        \"\"\"Apply the adjoint of the operator\n",
    "           add - boolean whether or not add to the data vector or zero it first\n",
    "           model - model space (domain)\n",
    "           data  - data space (range)\"\"\"\n",
    "        \n",
    "        raise Exception(\"Not implemented for now\")\n",
    "\n",
    "        \n",
    "@jit(nopython=True)\n",
    "def forward2D_EW(model, data):\n",
    "    for i2 in range(model.shape[0]):\n",
    "        for i in range(1, model.shape[2]):\n",
    "            data[i2,:, i] += model[i2,:,i] - model[i2, :, i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of the bay vector\n",
    "out=bay.clone()\n",
    "\n",
    "#create a version of the operaor\n",
    "op=deriv_EW(bay)\n",
    "\n",
    "#Apply the operator\n",
    "op.forward(False,bay,out)\n",
    "\n",
    "#View the result\n",
    "outP=Grey(out,label1=\"N-S\",label2=\"E-W\",width=500,height=700)\n",
    "outP.image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genericSolver.pyOperator import Operator\n",
    "from genericSolver import pyVector\n",
    "from numba import jit\n",
    "\n",
    "class deriv_lap(Operator):\n",
    "    \"\"\"A simple operator that applies a derivative along both axes\"\"\"\n",
    "    def __init__(self,domain):\n",
    "        \"\"\"Initialization an operator \"\"\"\n",
    "        \n",
    "        if not isinstance(domain,pyVector.vector): \n",
    "            raise Exception(\"Expecting a python vector\")\n",
    "        \n",
    "        #Store that vector space of the domain and range\n",
    "        super().__init__(domain,domain)\n",
    "        \n",
    "    def forward(self,add,model,data):\n",
    "        \"\"\"Apply the operator\n",
    "           add - boolean whether or not add to the data vector or zero it first\n",
    "           model - model space (domain)\n",
    "           data  - data space (range)\"\"\"\n",
    "        \n",
    "        #Make sure the model and data match the vectorspace the operator was initialized with\n",
    "        self.checkDomainRange(model,data)\n",
    "        \n",
    "        #Zero the data if add -false\n",
    "        if not add:\n",
    "            data.zero()\n",
    "        \n",
    "        forward2D_lap(model.getNdArray(),data.getNdArray())\n",
    "\n",
    "        \n",
    "    def adjoint(self,add,model,data):\n",
    "        \"\"\"Apply the adjoint of the operator\n",
    "           add - boolean whether or not add to the data vector or zero it first\n",
    "           model - model space (domain)\n",
    "           data  - data space (range)\"\"\"\n",
    "        \n",
    "        raise Exception(\"Not implemented for now\")\n",
    "\n",
    "        \n",
    "@jit(nopython=True)\n",
    "def forward2D_lap(model, data):\n",
    "    for i2 in range(model.shape[0]):\n",
    "        for i in range(1, model.shape[1]-1):\n",
    "            for j in range(1, model.shape[2]-1):\n",
    "                data[i2,i,j] += 4 * model[i2,i,j] - model[i2,i-1,j] - model[i2,i+1,j] - model[i2,i,j-1] - model[i2,i,j+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of the bay vector\n",
    "out=bay.clone()\n",
    "\n",
    "#create a version of the operaor\n",
    "op=deriv_lap(bay)\n",
    "\n",
    "#Apply the operator\n",
    "op.forward(False,bay,out)\n",
    "\n",
    "#View the result\n",
    "outP=Grey(out,label1=\"N-S\",label2=\"E-W\",width=500,height=700)\n",
    "outP.image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-oHlK32gzYw"
   },
   "source": [
    "## Extra Lab (Wizards only)\n",
    "In chapter 1 of GIEE you first learn about filtering.\n",
    "Next you learn about linear interpolation.\n",
    "This is an exercise where you try to put the two together.\n",
    "I give you lots of hints, then we talk about it.\n",
    "This is the first year this assignment is given,\n",
    "so, I have little idea how difficult you will find it.\n",
    "PLEASE LIMIT YOURSELF TO TWO HOURS.\n",
    "Do not expect to finish.\n",
    "Please turn it in on time.\n",
    "We will discuss it in subsequent class periods until we all know the answer.\n",
    "\n",
    "### Background\n",
    "We want to have filters that change their impulse response with time.\n",
    "The obvious code seems to require big memory with size being this product:\n",
    "data length times maximum filter lag.\n",
    "This isn't bad in one physical dimension, such as time, but is oppressive\n",
    "in higher spatial dimensions, such as in $(t,x)$, or $(t,x,z)$.\n",
    "But here, as warm up, we try to put it together in time alone.\n",
    "\n",
    "Fortunately, applications calling for time (and space) variable filters\n",
    "generally want the filter to change slowly with time.\n",
    "Thus we envision parameterizing filters by a coarse mesh (widely spaced time points).\n",
    "From this coarse mesh, linear interpolation finds the effective filter\n",
    "at each point in time.\n",
    "\n",
    "### Exercise\n",
    "Write a python code,\n",
    "to define time-variable convolution with a filter linearly interpolated from a coarse mesh.\n",
    "Ignore the adjoint.\n",
    "You are invited to discuss this problem with others before class.\n",
    "LIMIT YOUR TIME ON THIS PROBLEM TO TWO HOURS.\n",
    "\n",
    "## Hints\n",
    "\n",
    "The equation for filtering data $x(t)$ with filter $b(\\tau)$ is\n",
    "\\begin{equation}\n",
    "y(t) \\quad=\\quad \\int b(\\tau)\\, x(t-\\tau)\n",
    "\\end{equation}\n",
    "Practitioners will love it if we give them a filter changing with time:\n",
    "\\begin{equation}\n",
    "\\label{eqn:tvdecon0}\n",
    "y(t) \\quad=\\quad \\int b(\\tau,t)\\, x(t-\\tau)\n",
    "\\end{equation}\n",
    "The convolution part looks like\n",
    "\n",
    "do t    {     \n",
    ">do tau {\n",
    "> > if operator itself    \n",
    "> > >     y(t) +=  b(tau,t* x(t-tau)       \n",
    "\n",
    "\n",
    "\n",
    "The declarations at the beginning of the code can\n",
    "make it work like\n",
    "like $\\bf y = \\bf B\\bf x$ or\n",
    "like $\\bf y = \\bf X\\bf b$.\n",
    "\n",
    "\n",
    "How do we think about $b(\\tau,t)$?\n",
    "It's evidently an array, but not really.  It's more like an outer product.\n",
    "Using matrices, we might write it as\n",
    "\\begin{eqnarray}\n",
    "b(\\tau,t) \\quad=\\quad \n",
    "\t\\left[\n",
    "\t\t\\begin{array}{c}\n",
    "\t\t\t\\vdots \\\\\n",
    "\t\t\t\\bf b_i \\\\\n",
    "\t\t\t\\vdots\n",
    "\t\t\\end{array}\n",
    "\t\\right]\n",
    "\t\\left[ \\begin{array}{ccccc} 1.0 & .9 & .8 \\cdots & 0.0 \\end{array} \\right]\n",
    "\\ +\\ \n",
    "\t\\left[\n",
    "\t\t\\begin{array}{c}\n",
    "\t\t\t\\vdots \\\\\n",
    "\t\t\t\\bf b_{i+1} \\\\\n",
    "\t\t\t\\vdots\n",
    "\t\t\\end{array}\n",
    "\t\\right]\n",
    "\t\\left[ \\begin{array}{ccccc} .0 & .1 & .2 &\\cdots & 1.0 \\end{array} \\right]\n",
    "\\end{eqnarray}\n",
    "where the idea is that $\\bf b_i$ represents the filter at the previous mesh level\n",
    "and $\\bf b_{i+1}$ at the next level.\n",
    "Filter lag is on the vertical axis while time $t$ is on the horizontal.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFmuk34ZgzYw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def convTimeInvariant(signal, kernel, result, add = False):\n",
    "    ''' Convolution of a time invariant kernel with a time series\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : 1D numpy array\n",
    "        The time series to convolve\n",
    "    kernel : 1D numpy array\n",
    "        The time invariant kernel\n",
    "    result : 1D numpy array\n",
    "        The output array with the same size as signal + len(kernel) - 1\n",
    "    add : bool, optional\n",
    "        If True, add the result to result, otherwise overwrite result\n",
    "    '''\n",
    "\n",
    "    # get and check the size of the input\n",
    "    nt = signal.shape[0]\n",
    "    ntau = kernel.shape[0]\n",
    "    \n",
    "    if result.shape[0] != nt + ntau - 1:\n",
    "        raise ValueError('result has the wrong size')\n",
    "\n",
    "    # clear y if not add\n",
    "    if not add:\n",
    "        result[:] = 0.\n",
    "\n",
    "    # perform the convolution\n",
    "    for it in range(nt):\n",
    "        for itau in range(ntau):\n",
    "            result[it + itau] += kernel[itau] * signal[it]\n",
    "\n",
    "\n",
    "def convTimeVariant(signal, kernel, kernel_time, result, add = False):\n",
    "    ''' Convolution of a time variant kernel with a time series. The kernel is \n",
    "        represented by a coarse grid in time, and a linear interpolation is used \n",
    "        to evaluate the kernel at the time of the convolution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : 1D numpy array\n",
    "        The time series to convolve\n",
    "    kernel : 2D numpy array (ntau, nsam)\n",
    "        The coarse grid of the kernel\n",
    "    kernel_time : 1D numpy array (nsam)\n",
    "        The time axis of the kernel\n",
    "    result : 1D numpy array\n",
    "        The output array with the same size as result + len(kernel) - 1\n",
    "    add : bool, optional\n",
    "        If True, add the result to result, otherwise overwrite result\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Currently, the kernel_time contains the time grid of the kernel instead of the real time asxis\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # get and check the size of the input\n",
    "    nt   = signal.shape[0]\n",
    "    ntau = kernel.shape[0]\n",
    "    nsam = kernel.shape[1]\n",
    "    \n",
    "    \n",
    "    if result.shape[0] != nt + ntau - 1:\n",
    "        raise ValueError('result has the wrong size')\n",
    "        \n",
    "    if kernel_time.shape[0] != nsam:\n",
    "        raise ValueError('kernel_time has the wrong size')\n",
    "    \n",
    "    # clear y if not add\n",
    "    if not add:\n",
    "        result[:] = 0.\n",
    "\n",
    "    \n",
    "    for it in range(nt):        \n",
    "        \n",
    "        # locate the current time in the kernel time axis and choose the right kernel\n",
    "        if it < kernel_time[0]:\n",
    "            kernel_in_use = kernel[:, 0]\n",
    "        \n",
    "        elif it >= kernel_time[-1]:\n",
    "            kernel_in_use = kernel[:, -1]\n",
    "        \n",
    "        else:\n",
    "            it1 = np.where(kernel_time <= it)[0][-1]\n",
    "            it2 = it1 + 1\n",
    "            kernel_in_use = (kernel[:, it1] * (kernel_time[it2] - it) + kernel[:, it2] * (it - kernel_time[it1])) / (kernel_time[it2] - kernel_time[it1])        \n",
    "        \n",
    "        # perform the convolution using the kernel derived from the coarse grid in time with linear interpolation\n",
    "        for itau in range(ntau):\n",
    "            result[it + itau] += kernel_in_use[itau] * signal[it]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal\n",
    "my_signal = np.array([20, 22, 21, 25, 23, 24, 20, 21, 22, 25, 26, 27])\n",
    "\n",
    "# Moving average filter\n",
    "my_filter = np.array([1/3, 1/3, 1/3])\n",
    "\n",
    "# Result array\n",
    "my_result = np.zeros(my_signal.shape[0] + my_filter.shape[0] - 1)\n",
    "\n",
    "# Perform the convolution \n",
    "convTimeInvariant(my_signal, my_filter, my_result, add = False)\n",
    "\n",
    "plt.plot(my_signal)\n",
    "plt.plot(my_result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal\n",
    "my_signal = np.array([20, 22, 21, 25, 23, 24, 20, 21, 22, 25, 26, 27])\n",
    "\n",
    "# Moving average filter\n",
    "my_filter = np.array([[1/2, 1/4, 1/4], [1/3, 1/3, 1/3], [1/4, 1/4, 1/2], [1, 0, 0]]).T\n",
    "my_filter_time = np.array([2, 3, 5, 12])\n",
    "\n",
    "# Result array\n",
    "my_result2 = np.zeros(my_signal.shape[0] + my_filter.shape[0] - 1)\n",
    "\n",
    "# Perform the convolution \n",
    "convTimeVariant(my_signal, my_filter, my_filter_time, my_result2, add = False)\n",
    "\n",
    "plt.plot(my_signal)\n",
    "plt.plot(my_result)\n",
    "plt.plot(my_result2, '--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
